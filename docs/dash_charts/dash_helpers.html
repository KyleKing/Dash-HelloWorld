<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>dash_charts.dash_helpers API documentation</title>
<meta name="description" content="Helpers for building Dash applications." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>
a {
text-decoration: underline;
}
h1,h2,h3,h4 {
font-weight: 400;
}
h2 {
margin: 0.50em 0 .25em 0;
}
dd p {
margin: 5px 0;
}
dl dl:last-child {
margin-bottom: 2.5em;
}
main {
margin-bottom: 80vh;
}
#content {
max-width: 1100px;
}
.source summary {
background-color: #fafafa; /* match HLJS background */
padding: 1px 5px;
}
.source summary:focus {
outline: none !important;
}
.source pre {
background-color: #fafafa; /* match HLJS background */
}
.source pre code {
padding-bottom: 1em;
}
table, th, td {
border: 1px solid #d4d4d4;
padding: 0 5px;
}
</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dash_charts.dash_helpers</code></h1>
</header>
<section id="section-intro">
<p>Helpers for building Dash applications.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Helpers for building Dash applications.&#34;&#34;&#34;

import argparse
import csv
import json
import sqlite3
import time
from contextlib import ContextDecorator
from datetime import datetime
from pathlib import Path

import dataset
import pandas as pd
from cerberus import Validator


def validate(document, schema, **validator_kwargs):
    &#34;&#34;&#34;Validate a data structure. Return errors if any found.

    Cerberus Documentation: https://docs.python-cerberus.org/en/stable/validation-rules.html

    Args:
        document: data structure to validate
        schema: expected structure
        validator_kwargs: additional keyword arguments for Validator class

    Returns:
        list: validation errors

    &#34;&#34;&#34;
    validator = Validator(schema, **validator_kwargs)
    validator.validate(document)
    return validator.errors


def parse_dash_cli_args():  # pragma: no cover
    &#34;&#34;&#34;Configure the CLI options for Dash applications.

    Returns:
        dict: keyword arguments for Dash

    &#34;&#34;&#34;
    parser = argparse.ArgumentParser(description=&#39;Process Dash Parameters.&#39;)
    parser.add_argument(&#39;--port&#39;, type=int, default=8050,
                        help=&#39;Pass port number to Dash server. Default is 8050&#39;)
    parser.add_argument(&#39;--nodebug&#39;, action=&#39;store_true&#39;, default=False,
                        help=&#39;If set, will disable debug mode. Default is to set `debug=True`&#39;)
    args = parser.parse_args()
    return {&#39;port&#39;: args.port, &#39;debug&#39;: not args.nodebug}


def json_dumps_compact(data):
    &#34;&#34;&#34;Format provided dictionary into compact JSON. Lists will be in one line rather than split on new lines.

    Args:
        data: JSON-serializable dictionary

    Returns:
        str: JSON-formatted string with lists compacted into a single line

    &#34;&#34;&#34;
    clean_data = {}
    # Check each key/value pair to determine if any intermediary strings are needed for later formatting
    for key, raw in data.items():
        if isinstance(raw, list):
            values = [f&#39;``{value}``&#39; if isinstance(value, str) else value for value in raw]
            clean_data[key] = &#39;[&#39; + &#39;,&#39;.join(map(str, values)) + &#39;]&#39;
        else:
            clean_data[key] = raw
    # Format the dictionary into JSON and replace the special characters used as intermediaries
    raw_json = json.dumps(clean_data, indent=4, separators=(&#39;,&#39;, &#39;: &#39;), sort_keys=True)
    return (raw_json
            .replace(&#39;: &#34;[&#39;, &#39;: [&#39;)
            .replace(&#39;]&#34;&#39;, &#39;]&#39;)
            .replace(&#39;``&#39;, &#39;&#34;&#39;)
            .replace(&#34;&#39;&#34;, &#39;&#34;&#39;))


def write_pretty_json(filename, obj):
    &#34;&#34;&#34;Write indented JSON file.

    Args:
        filename: Path or plain string filename to write (should end with `.json`)
        obj: JSON object to write

    &#34;&#34;&#34;
    Path(filename).write_text(json.dumps(obj, indent=4, separators=(&#39;,&#39;, &#39;: &#39;)))


# ----------------------------------------------------------------------------------------------------------------------
# sqlite3


class SQLConnection(ContextDecorator):
    &#34;&#34;&#34;Ensure the SQLite connection is properly opened and closed.&#34;&#34;&#34;

    def __init__(self, db_file):
        &#34;&#34;&#34;Initialize context wrapper.

        Args:
            db_file: Path to a SQLite file

        &#34;&#34;&#34;
        self.conn = None
        self.database_path = db_file

    def __enter__(self):
        &#34;&#34;&#34;Connect to the database and return connection reference.

        Returns:
            dict: connection to sqlite database

        &#34;&#34;&#34;
        self.conn = sqlite3.connect(self.database_path)
        return self.conn

    def __exit__(self, exc_type, exc_value, traceback):
        &#34;&#34;&#34;Close connection.&#34;&#34;&#34;  # noqa: DAR101
        self.conn.close()


def list_sql_tables(db_file):
    &#34;&#34;&#34;Return all table names from the SQL database.

    Args:
        db_file: path to SQLite database file

    Returns:
        list: of unique table names in the SQL database

    &#34;&#34;&#34;
    with SQLConnection(db_file) as conn:
        cursor = conn.cursor()
        cursor.execute(&#39;SELECT name FROM sqlite_master WHERE TYPE = &#34;table&#34;&#39;)
        return [names[0] for names in cursor.fetchall()]


# ----------------------------------------------------------------------------------------------------------------------
# dataset

META_TABLE_NAME = &#39;meta&#39;
&#34;&#34;&#34;Name of the Meta-Data table in a typical SQLite database.&#34;&#34;&#34;


class DBConnect:
    &#34;&#34;&#34;Manage database connection since closing connection isn&#39;t possible.&#34;&#34;&#34;

    database_path = None
    &#34;&#34;&#34;Path to the local storage SQLite database file. Initialize in `__init__()`.&#34;&#34;&#34;

    _db = None

    @property
    def db(self):
        &#34;&#34;&#34;Return connection to database. Will create new connection if one does not exist already.

        Returns:
            dict: `dataset` database instance

        &#34;&#34;&#34;
        if self._db is None:
            self._db = dataset.connect(f&#39;sqlite:///{self.database_path}&#39;)
        return self._db

    def __init__(self, database_path):
        &#34;&#34;&#34;Store the database path and ensure the parent directory exists.

        Args:
            database_path: Path to the SQLite file

        &#34;&#34;&#34;
        self.database_path = database_path.resolve()
        self.database_path.parent.mkdir(exist_ok=True)

    def new_table(self, table_name):
        &#34;&#34;&#34;Create a table. Drop a table if one existed before.

        Args:
            table_name: string table name to create

        Returns:
            table: a dataset Table instance

        &#34;&#34;&#34;
        if table_name in self.db.tables:
            self.db[table_name].drop()
        return self.db.create_table(table_name)

    def close(self):
        &#34;&#34;&#34;Safely disconnect and release the SQLite file.&#34;&#34;&#34;
        self.db.executable.close()
        self._db = None


class DBConnection(ContextDecorator):
    &#34;&#34;&#34;Ensure the DBConnect connection is properly opened and closed.&#34;&#34;&#34;

    def __init__(self, db_file):
        &#34;&#34;&#34;Initialize context wrapper.

        Args:
            db_file: Path to the SQLite file

        &#34;&#34;&#34;
        self.conn = None
        self.database_path = db_file

    def __enter__(self):
        &#34;&#34;&#34;Connect to the database and return connection reference.

        Returns:
            dict: connection to sqlite database

        &#34;&#34;&#34;
        self.conn = DBConnect(self.database_path)
        return self.conn

    def __exit__(self, exc_type, exc_value, traceback):
        &#34;&#34;&#34;Close connection.&#34;&#34;&#34;  # noqa: DAR101
        self.conn.close()


def rm_brs(line):
    &#34;&#34;&#34;Replace all whitespace (line breaks, etc) with spaces.&#34;&#34;&#34;  # noqa: DAR101,DAR201
    return &#39; &#39;.join(line.split())


def uniq_table_id():
    &#34;&#34;&#34;Return a unique table ID based on the current time in ms.

    Returns:
        str: in format `U&lt;timestamp_ns&gt;`

    &#34;&#34;&#34;
    return f&#39;U{time.time_ns()}&#39;


def write_csv(csv_path, rows):
    &#34;&#34;&#34;Write a csv file with appropriate line terminator and encoding.

    Args:
        csv_path: path to CSV file
        rows: list of lists to write to CSV file

    &#34;&#34;&#34;
    with open(csv_path, &#39;w&#39;, newline=&#39;\n&#39;, encoding=&#39;utf-8&#39;) as csv_file:
        writer = csv.writer(csv_file, delimiter=&#39;,&#39;, quoting=csv.QUOTE_MINIMAL)
        for row in rows:
            writer.writerow(row)


def export_table_as_csv(csv_filename, table):
    &#34;&#34;&#34;Create a CSV file summarizing a table of a `dataset` database.

    Args:
        csv_filename: Path to csv file
        table: table from dataset database

    &#34;&#34;&#34;
    rows = [[*table.columns]]
    for row in table:
        rows.append([*row.values()])
    write_csv(csv_filename, rows)


def safe_col_name(args_pair):
    &#34;&#34;&#34;Ensure that the column name is safe for SQL (unique value, no spaces, no trailing punctuation).

    Typically called with `df.columns = [*map(safe_col_name, enumerate(df.columns.to_list()))]`

    Args:
        args_pair: tuple of arguments from map function in `(idx, col)`

    Returns:
        string: safely formatted string for SQLite

    &#34;&#34;&#34;
    idx, col = args_pair
    col = col.strip().replace(&#39; &#39;, &#39;_&#39;).replace(&#39;.&#39;, &#39;_&#39;).replace(&#39;,&#39;, &#39;_&#39;)
    return str(idx) if col == &#39;&#39; else col


def store_reference_tables(db_file, data_dicts, meta_table_name=META_TABLE_NAME):
    &#34;&#34;&#34;Store multi-dimensionsal data in a SQLite database.

    WARN: This will append to the META_TABLE_NAME without checking for duplicates. Handling de-duping separately

    Args:
        db_file: Path to a `.db` file
        data_dicts: all data to be stored in SQLite. Can contain Pandas dataframes
        meta_table_name: optional name of the main SQLite table. Default is `META_TABLE_NAME`

    &#34;&#34;&#34;
    with DBConnection(db_file) as data_db:
        meta_table = []
        unique = uniq_table_id()
        for dict_idx, data_dict in enumerate(data_dicts):
            lookup = {}
            for key_idx, (key, value) in enumerate(data_dict.items()):
                if isinstance(value, pd.DataFrame):
                    table_name = f&#39;{unique}D{dict_idx}K{key_idx}&#39;
                    table = data_db.new_table(table_name)
                    value.columns = [*map(safe_col_name, enumerate(value.columns.to_list()))]
                    table.insert_many([*value.to_dict(orient=&#39;records&#39;)])
                    lookup[key] = table_name
                else:
                    lookup[key] = value
            meta_table.append(lookup)

        table_main = data_db.db.create_table(meta_table_name)
        table_main.insert_many(meta_table)


def get_table(db_file, table_name, drop_id_col=True):
    &#34;&#34;&#34;Retrieve the meta table as a Pandas dataframe.

    Args:
        db_file: Path to a `.db` file
        table_name: SQLite table name
        drop_id_col: if True, drop the `id` column from SQL. Default is True

    Returns:
        df_table: pandas dataframe for the values in the specified table (`meta_table_name`)

    &#34;&#34;&#34;
    with DBConnection(db_file) as data_db:
        df_table = pd.DataFrame([*data_db.db[table_name].all()])
    # Optionally remove the &#39;id&#39; column added in the SQL database
    if drop_id_col:
        df_table = df_table.drop([&#39;id&#39;], axis=1)
    return df_table  # noqa: R504


# ----------------------------------------------------------------------------------------------------------------------
# General Helpers


def enable_verbose_pandas():
    &#34;&#34;&#34;Update global pandas configuration for printed dataframes.&#34;&#34;&#34;
    # Enable all columns to be displayed at once (or tweak to set a new limit)
    pd.set_option(&#39;display.max_columns&#39;, None)
    pd.set_option(&#39;display.width&#39;, None)
    pd.set_option(&#39;display.max_colwidth&#39;, None)

    # Optionally modify number of rows shown
    pd.set_option(&#39;display.max_rows&#39;, None)


def graph_return(resp, keys):
    &#34;&#34;&#34;Based on concepts of GraphQL, return specified subset of response.

    Args:
        resp: dictionary with values from function
        keys: list of keynames from the resp dictionary

    Returns:
        the `resp` dictionary with only the keys specified in the `keys` list

    Raises:
        RuntimeError: if `keys` is not a list or tuple

    &#34;&#34;&#34;
    if not (len(keys) and isinstance(keys, (list, tuple))):
        raise RuntimeError(f&#39;Expected list of keys for: `{resp.items()}`, but received `{keys}`&#39;)
    ordered_responses = [resp.get(key, None) for key in keys]
    return ordered_responses if len(ordered_responses) &gt; 1 else ordered_responses[0]


def get_unix(str_ts, date_format):
    &#34;&#34;&#34;Get unix timestamp from a string timestamp in date_format.

    Args:
        str_ts: string timestamp in `date_format`
        date_format: datetime time stamp format

    Returns:
        int: unix timestamp

    &#34;&#34;&#34;
    return datetime.strptime(str_ts, date_format).timestamp()


def format_unix(unix_ts, date_format):
    &#34;&#34;&#34;Format unix timestamp as a string timestamp in date_format.

    Args:
        unix_ts: unix timestamp
        date_format: datetime time stamp format

    Returns:
        string: formatted timestamp in `date_format`

    &#34;&#34;&#34;
    return datetime.fromtimestamp(unix_ts).strftime(date_format)</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="dash_charts.dash_helpers.META_TABLE_NAME"><code class="name">var <span class="ident">META_TABLE_NAME</span></code></dt>
<dd>
<div class="desc"><p>Name of the Meta-Data table in a typical SQLite database.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dash_charts.dash_helpers.enable_verbose_pandas"><code class="name flex">
<span>def <span class="ident">enable_verbose_pandas</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Update global pandas configuration for printed dataframes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enable_verbose_pandas():
    &#34;&#34;&#34;Update global pandas configuration for printed dataframes.&#34;&#34;&#34;
    # Enable all columns to be displayed at once (or tweak to set a new limit)
    pd.set_option(&#39;display.max_columns&#39;, None)
    pd.set_option(&#39;display.width&#39;, None)
    pd.set_option(&#39;display.max_colwidth&#39;, None)

    # Optionally modify number of rows shown
    pd.set_option(&#39;display.max_rows&#39;, None)</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.export_table_as_csv"><code class="name flex">
<span>def <span class="ident">export_table_as_csv</span></span>(<span>csv_filename, table)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a CSV file summarizing a table of a <code>dataset</code> database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>csv_filename</code></strong></dt>
<dd>Path to csv file</dd>
<dt><strong><code>table</code></strong></dt>
<dd>table from dataset database</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_table_as_csv(csv_filename, table):
    &#34;&#34;&#34;Create a CSV file summarizing a table of a `dataset` database.

    Args:
        csv_filename: Path to csv file
        table: table from dataset database

    &#34;&#34;&#34;
    rows = [[*table.columns]]
    for row in table:
        rows.append([*row.values()])
    write_csv(csv_filename, rows)</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.format_unix"><code class="name flex">
<span>def <span class="ident">format_unix</span></span>(<span>unix_ts, date_format)</span>
</code></dt>
<dd>
<div class="desc"><p>Format unix timestamp as a string timestamp in date_format.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>unix_ts</code></strong></dt>
<dd>unix timestamp</dd>
<dt><strong><code>date_format</code></strong></dt>
<dd>datetime time stamp format</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>formatted timestamp in <code>date_format</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def format_unix(unix_ts, date_format):
    &#34;&#34;&#34;Format unix timestamp as a string timestamp in date_format.

    Args:
        unix_ts: unix timestamp
        date_format: datetime time stamp format

    Returns:
        string: formatted timestamp in `date_format`

    &#34;&#34;&#34;
    return datetime.fromtimestamp(unix_ts).strftime(date_format)</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.get_table"><code class="name flex">
<span>def <span class="ident">get_table</span></span>(<span>db_file, table_name, drop_id_col=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve the meta table as a Pandas dataframe.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db_file</code></strong></dt>
<dd>Path to a <code>.db</code> file</dd>
<dt><strong><code>table_name</code></strong></dt>
<dd>SQLite table name</dd>
<dt><strong><code>drop_id_col</code></strong></dt>
<dd>if True, drop the <code>id</code> column from SQL. Default is True</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>df_table</code></dt>
<dd>pandas dataframe for the values in the specified table (<code>meta_table_name</code>)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_table(db_file, table_name, drop_id_col=True):
    &#34;&#34;&#34;Retrieve the meta table as a Pandas dataframe.

    Args:
        db_file: Path to a `.db` file
        table_name: SQLite table name
        drop_id_col: if True, drop the `id` column from SQL. Default is True

    Returns:
        df_table: pandas dataframe for the values in the specified table (`meta_table_name`)

    &#34;&#34;&#34;
    with DBConnection(db_file) as data_db:
        df_table = pd.DataFrame([*data_db.db[table_name].all()])
    # Optionally remove the &#39;id&#39; column added in the SQL database
    if drop_id_col:
        df_table = df_table.drop([&#39;id&#39;], axis=1)
    return df_table  # noqa: R504</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.get_unix"><code class="name flex">
<span>def <span class="ident">get_unix</span></span>(<span>str_ts, date_format)</span>
</code></dt>
<dd>
<div class="desc"><p>Get unix timestamp from a string timestamp in date_format.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>str_ts</code></strong></dt>
<dd>string timestamp in <code>date_format</code></dd>
<dt><strong><code>date_format</code></strong></dt>
<dd>datetime time stamp format</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>unix timestamp</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_unix(str_ts, date_format):
    &#34;&#34;&#34;Get unix timestamp from a string timestamp in date_format.

    Args:
        str_ts: string timestamp in `date_format`
        date_format: datetime time stamp format

    Returns:
        int: unix timestamp

    &#34;&#34;&#34;
    return datetime.strptime(str_ts, date_format).timestamp()</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.graph_return"><code class="name flex">
<span>def <span class="ident">graph_return</span></span>(<span>resp, keys)</span>
</code></dt>
<dd>
<div class="desc"><p>Based on concepts of GraphQL, return specified subset of response.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>resp</code></strong></dt>
<dd>dictionary with values from function</dd>
<dt><strong><code>keys</code></strong></dt>
<dd>list of keynames from the resp dictionary</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>the <code>resp</code> dictionary with only the keys specified in the <code>keys</code> list</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>if <code>keys</code> is not a list or tuple</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def graph_return(resp, keys):
    &#34;&#34;&#34;Based on concepts of GraphQL, return specified subset of response.

    Args:
        resp: dictionary with values from function
        keys: list of keynames from the resp dictionary

    Returns:
        the `resp` dictionary with only the keys specified in the `keys` list

    Raises:
        RuntimeError: if `keys` is not a list or tuple

    &#34;&#34;&#34;
    if not (len(keys) and isinstance(keys, (list, tuple))):
        raise RuntimeError(f&#39;Expected list of keys for: `{resp.items()}`, but received `{keys}`&#39;)
    ordered_responses = [resp.get(key, None) for key in keys]
    return ordered_responses if len(ordered_responses) &gt; 1 else ordered_responses[0]</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.json_dumps_compact"><code class="name flex">
<span>def <span class="ident">json_dumps_compact</span></span>(<span>data)</span>
</code></dt>
<dd>
<div class="desc"><p>Format provided dictionary into compact JSON. Lists will be in one line rather than split on new lines.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong></dt>
<dd>JSON-serializable dictionary</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>JSON-formatted string with lists compacted into a single line</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def json_dumps_compact(data):
    &#34;&#34;&#34;Format provided dictionary into compact JSON. Lists will be in one line rather than split on new lines.

    Args:
        data: JSON-serializable dictionary

    Returns:
        str: JSON-formatted string with lists compacted into a single line

    &#34;&#34;&#34;
    clean_data = {}
    # Check each key/value pair to determine if any intermediary strings are needed for later formatting
    for key, raw in data.items():
        if isinstance(raw, list):
            values = [f&#39;``{value}``&#39; if isinstance(value, str) else value for value in raw]
            clean_data[key] = &#39;[&#39; + &#39;,&#39;.join(map(str, values)) + &#39;]&#39;
        else:
            clean_data[key] = raw
    # Format the dictionary into JSON and replace the special characters used as intermediaries
    raw_json = json.dumps(clean_data, indent=4, separators=(&#39;,&#39;, &#39;: &#39;), sort_keys=True)
    return (raw_json
            .replace(&#39;: &#34;[&#39;, &#39;: [&#39;)
            .replace(&#39;]&#34;&#39;, &#39;]&#39;)
            .replace(&#39;``&#39;, &#39;&#34;&#39;)
            .replace(&#34;&#39;&#34;, &#39;&#34;&#39;))</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.list_sql_tables"><code class="name flex">
<span>def <span class="ident">list_sql_tables</span></span>(<span>db_file)</span>
</code></dt>
<dd>
<div class="desc"><p>Return all table names from the SQL database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db_file</code></strong></dt>
<dd>path to SQLite database file</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>of unique table names in the SQL database</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def list_sql_tables(db_file):
    &#34;&#34;&#34;Return all table names from the SQL database.

    Args:
        db_file: path to SQLite database file

    Returns:
        list: of unique table names in the SQL database

    &#34;&#34;&#34;
    with SQLConnection(db_file) as conn:
        cursor = conn.cursor()
        cursor.execute(&#39;SELECT name FROM sqlite_master WHERE TYPE = &#34;table&#34;&#39;)
        return [names[0] for names in cursor.fetchall()]</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.parse_dash_cli_args"><code class="name flex">
<span>def <span class="ident">parse_dash_cli_args</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Configure the CLI options for Dash applications.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>keyword arguments for Dash</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_dash_cli_args():  # pragma: no cover
    &#34;&#34;&#34;Configure the CLI options for Dash applications.

    Returns:
        dict: keyword arguments for Dash

    &#34;&#34;&#34;
    parser = argparse.ArgumentParser(description=&#39;Process Dash Parameters.&#39;)
    parser.add_argument(&#39;--port&#39;, type=int, default=8050,
                        help=&#39;Pass port number to Dash server. Default is 8050&#39;)
    parser.add_argument(&#39;--nodebug&#39;, action=&#39;store_true&#39;, default=False,
                        help=&#39;If set, will disable debug mode. Default is to set `debug=True`&#39;)
    args = parser.parse_args()
    return {&#39;port&#39;: args.port, &#39;debug&#39;: not args.nodebug}</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.rm_brs"><code class="name flex">
<span>def <span class="ident">rm_brs</span></span>(<span>line)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all whitespace (line breaks, etc) with spaces.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rm_brs(line):
    &#34;&#34;&#34;Replace all whitespace (line breaks, etc) with spaces.&#34;&#34;&#34;  # noqa: DAR101,DAR201
    return &#39; &#39;.join(line.split())</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.safe_col_name"><code class="name flex">
<span>def <span class="ident">safe_col_name</span></span>(<span>args_pair)</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure that the column name is safe for SQL (unique value, no spaces, no trailing punctuation).</p>
<p>Typically called with <code>df.columns = [*map(safe_col_name, enumerate(df.columns.to_list()))]</code></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>args_pair</code></strong></dt>
<dd>tuple of arguments from map function in <code>(idx, col)</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>safely formatted string for SQLite</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def safe_col_name(args_pair):
    &#34;&#34;&#34;Ensure that the column name is safe for SQL (unique value, no spaces, no trailing punctuation).

    Typically called with `df.columns = [*map(safe_col_name, enumerate(df.columns.to_list()))]`

    Args:
        args_pair: tuple of arguments from map function in `(idx, col)`

    Returns:
        string: safely formatted string for SQLite

    &#34;&#34;&#34;
    idx, col = args_pair
    col = col.strip().replace(&#39; &#39;, &#39;_&#39;).replace(&#39;.&#39;, &#39;_&#39;).replace(&#39;,&#39;, &#39;_&#39;)
    return str(idx) if col == &#39;&#39; else col</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.store_reference_tables"><code class="name flex">
<span>def <span class="ident">store_reference_tables</span></span>(<span>db_file, data_dicts, meta_table_name='meta')</span>
</code></dt>
<dd>
<div class="desc"><p>Store multi-dimensionsal data in a SQLite database.</p>
<p>WARN: This will append to the META_TABLE_NAME without checking for duplicates. Handling de-duping separately</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db_file</code></strong></dt>
<dd>Path to a <code>.db</code> file</dd>
<dt><strong><code>data_dicts</code></strong></dt>
<dd>all data to be stored in SQLite. Can contain Pandas dataframes</dd>
<dt><strong><code>meta_table_name</code></strong></dt>
<dd>optional name of the main SQLite table. Default is <code><a title="dash_charts.dash_helpers.META_TABLE_NAME" href="#dash_charts.dash_helpers.META_TABLE_NAME">META_TABLE_NAME</a></code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def store_reference_tables(db_file, data_dicts, meta_table_name=META_TABLE_NAME):
    &#34;&#34;&#34;Store multi-dimensionsal data in a SQLite database.

    WARN: This will append to the META_TABLE_NAME without checking for duplicates. Handling de-duping separately

    Args:
        db_file: Path to a `.db` file
        data_dicts: all data to be stored in SQLite. Can contain Pandas dataframes
        meta_table_name: optional name of the main SQLite table. Default is `META_TABLE_NAME`

    &#34;&#34;&#34;
    with DBConnection(db_file) as data_db:
        meta_table = []
        unique = uniq_table_id()
        for dict_idx, data_dict in enumerate(data_dicts):
            lookup = {}
            for key_idx, (key, value) in enumerate(data_dict.items()):
                if isinstance(value, pd.DataFrame):
                    table_name = f&#39;{unique}D{dict_idx}K{key_idx}&#39;
                    table = data_db.new_table(table_name)
                    value.columns = [*map(safe_col_name, enumerate(value.columns.to_list()))]
                    table.insert_many([*value.to_dict(orient=&#39;records&#39;)])
                    lookup[key] = table_name
                else:
                    lookup[key] = value
            meta_table.append(lookup)

        table_main = data_db.db.create_table(meta_table_name)
        table_main.insert_many(meta_table)</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.uniq_table_id"><code class="name flex">
<span>def <span class="ident">uniq_table_id</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a unique table ID based on the current time in ms.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>in format <code>U&lt;timestamp_ns&gt;</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def uniq_table_id():
    &#34;&#34;&#34;Return a unique table ID based on the current time in ms.

    Returns:
        str: in format `U&lt;timestamp_ns&gt;`

    &#34;&#34;&#34;
    return f&#39;U{time.time_ns()}&#39;</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.validate"><code class="name flex">
<span>def <span class="ident">validate</span></span>(<span>document, schema, **validator_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Validate a data structure. Return errors if any found.</p>
<p>Cerberus Documentation: <a href="https://docs.python-cerberus.org/en/stable/validation-rules.html">https://docs.python-cerberus.org/en/stable/validation-rules.html</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>document</code></strong></dt>
<dd>data structure to validate</dd>
<dt><strong><code>schema</code></strong></dt>
<dd>expected structure</dd>
<dt><strong><code>validator_kwargs</code></strong></dt>
<dd>additional keyword arguments for Validator class</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>validation errors</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate(document, schema, **validator_kwargs):
    &#34;&#34;&#34;Validate a data structure. Return errors if any found.

    Cerberus Documentation: https://docs.python-cerberus.org/en/stable/validation-rules.html

    Args:
        document: data structure to validate
        schema: expected structure
        validator_kwargs: additional keyword arguments for Validator class

    Returns:
        list: validation errors

    &#34;&#34;&#34;
    validator = Validator(schema, **validator_kwargs)
    validator.validate(document)
    return validator.errors</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.write_csv"><code class="name flex">
<span>def <span class="ident">write_csv</span></span>(<span>csv_path, rows)</span>
</code></dt>
<dd>
<div class="desc"><p>Write a csv file with appropriate line terminator and encoding.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>csv_path</code></strong></dt>
<dd>path to CSV file</dd>
<dt><strong><code>rows</code></strong></dt>
<dd>list of lists to write to CSV file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_csv(csv_path, rows):
    &#34;&#34;&#34;Write a csv file with appropriate line terminator and encoding.

    Args:
        csv_path: path to CSV file
        rows: list of lists to write to CSV file

    &#34;&#34;&#34;
    with open(csv_path, &#39;w&#39;, newline=&#39;\n&#39;, encoding=&#39;utf-8&#39;) as csv_file:
        writer = csv.writer(csv_file, delimiter=&#39;,&#39;, quoting=csv.QUOTE_MINIMAL)
        for row in rows:
            writer.writerow(row)</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.write_pretty_json"><code class="name flex">
<span>def <span class="ident">write_pretty_json</span></span>(<span>filename, obj)</span>
</code></dt>
<dd>
<div class="desc"><p>Write indented JSON file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>Path or plain string filename to write (should end with <code>.json</code>)</dd>
<dt><strong><code>obj</code></strong></dt>
<dd>JSON object to write</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_pretty_json(filename, obj):
    &#34;&#34;&#34;Write indented JSON file.

    Args:
        filename: Path or plain string filename to write (should end with `.json`)
        obj: JSON object to write

    &#34;&#34;&#34;
    Path(filename).write_text(json.dumps(obj, indent=4, separators=(&#39;,&#39;, &#39;: &#39;)))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dash_charts.dash_helpers.DBConnect"><code class="flex name class">
<span>class <span class="ident">DBConnect</span></span>
<span>(</span><span>database_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Manage database connection since closing connection isn't possible.</p>
<p>Store the database path and ensure the parent directory exists.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>database_path</code></strong></dt>
<dd>Path to the SQLite file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DBConnect:
    &#34;&#34;&#34;Manage database connection since closing connection isn&#39;t possible.&#34;&#34;&#34;

    database_path = None
    &#34;&#34;&#34;Path to the local storage SQLite database file. Initialize in `__init__()`.&#34;&#34;&#34;

    _db = None

    @property
    def db(self):
        &#34;&#34;&#34;Return connection to database. Will create new connection if one does not exist already.

        Returns:
            dict: `dataset` database instance

        &#34;&#34;&#34;
        if self._db is None:
            self._db = dataset.connect(f&#39;sqlite:///{self.database_path}&#39;)
        return self._db

    def __init__(self, database_path):
        &#34;&#34;&#34;Store the database path and ensure the parent directory exists.

        Args:
            database_path: Path to the SQLite file

        &#34;&#34;&#34;
        self.database_path = database_path.resolve()
        self.database_path.parent.mkdir(exist_ok=True)

    def new_table(self, table_name):
        &#34;&#34;&#34;Create a table. Drop a table if one existed before.

        Args:
            table_name: string table name to create

        Returns:
            table: a dataset Table instance

        &#34;&#34;&#34;
        if table_name in self.db.tables:
            self.db[table_name].drop()
        return self.db.create_table(table_name)

    def close(self):
        &#34;&#34;&#34;Safely disconnect and release the SQLite file.&#34;&#34;&#34;
        self.db.executable.close()
        self._db = None</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dash_charts.dash_helpers.DBConnect.database_path"><code class="name">var <span class="ident">database_path</span></code></dt>
<dd>
<div class="desc"><p>Path to the local storage SQLite database file. Initialize in <code>__init__()</code>.</p></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="dash_charts.dash_helpers.DBConnect.db"><code class="name">var <span class="ident">db</span></code></dt>
<dd>
<div class="desc"><p>Return connection to database. Will create new connection if one does not exist already.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd><code>dataset</code> database instance</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def db(self):
    &#34;&#34;&#34;Return connection to database. Will create new connection if one does not exist already.

    Returns:
        dict: `dataset` database instance

    &#34;&#34;&#34;
    if self._db is None:
        self._db = dataset.connect(f&#39;sqlite:///{self.database_path}&#39;)
    return self._db</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dash_charts.dash_helpers.DBConnect.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Safely disconnect and release the SQLite file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;Safely disconnect and release the SQLite file.&#34;&#34;&#34;
    self.db.executable.close()
    self._db = None</code></pre>
</details>
</dd>
<dt id="dash_charts.dash_helpers.DBConnect.new_table"><code class="name flex">
<span>def <span class="ident">new_table</span></span>(<span>self, table_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a table. Drop a table if one existed before.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>table_name</code></strong></dt>
<dd>string table name to create</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>table</code></dt>
<dd>a dataset Table instance</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_table(self, table_name):
    &#34;&#34;&#34;Create a table. Drop a table if one existed before.

    Args:
        table_name: string table name to create

    Returns:
        table: a dataset Table instance

    &#34;&#34;&#34;
    if table_name in self.db.tables:
        self.db[table_name].drop()
    return self.db.create_table(table_name)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dash_charts.dash_helpers.DBConnection"><code class="flex name class">
<span>class <span class="ident">DBConnection</span></span>
<span>(</span><span>db_file)</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure the DBConnect connection is properly opened and closed.</p>
<p>Initialize context wrapper.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db_file</code></strong></dt>
<dd>Path to the SQLite file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DBConnection(ContextDecorator):
    &#34;&#34;&#34;Ensure the DBConnect connection is properly opened and closed.&#34;&#34;&#34;

    def __init__(self, db_file):
        &#34;&#34;&#34;Initialize context wrapper.

        Args:
            db_file: Path to the SQLite file

        &#34;&#34;&#34;
        self.conn = None
        self.database_path = db_file

    def __enter__(self):
        &#34;&#34;&#34;Connect to the database and return connection reference.

        Returns:
            dict: connection to sqlite database

        &#34;&#34;&#34;
        self.conn = DBConnect(self.database_path)
        return self.conn

    def __exit__(self, exc_type, exc_value, traceback):
        &#34;&#34;&#34;Close connection.&#34;&#34;&#34;  # noqa: DAR101
        self.conn.close()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>contextlib.ContextDecorator</li>
</ul>
</dd>
<dt id="dash_charts.dash_helpers.SQLConnection"><code class="flex name class">
<span>class <span class="ident">SQLConnection</span></span>
<span>(</span><span>db_file)</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure the SQLite connection is properly opened and closed.</p>
<p>Initialize context wrapper.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db_file</code></strong></dt>
<dd>Path to a SQLite file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SQLConnection(ContextDecorator):
    &#34;&#34;&#34;Ensure the SQLite connection is properly opened and closed.&#34;&#34;&#34;

    def __init__(self, db_file):
        &#34;&#34;&#34;Initialize context wrapper.

        Args:
            db_file: Path to a SQLite file

        &#34;&#34;&#34;
        self.conn = None
        self.database_path = db_file

    def __enter__(self):
        &#34;&#34;&#34;Connect to the database and return connection reference.

        Returns:
            dict: connection to sqlite database

        &#34;&#34;&#34;
        self.conn = sqlite3.connect(self.database_path)
        return self.conn

    def __exit__(self, exc_type, exc_value, traceback):
        &#34;&#34;&#34;Close connection.&#34;&#34;&#34;  # noqa: DAR101
        self.conn.close()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>contextlib.ContextDecorator</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dash_charts" href="index.html">dash_charts</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="dash_charts.dash_helpers.META_TABLE_NAME" href="#dash_charts.dash_helpers.META_TABLE_NAME">META_TABLE_NAME</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dash_charts.dash_helpers.enable_verbose_pandas" href="#dash_charts.dash_helpers.enable_verbose_pandas">enable_verbose_pandas</a></code></li>
<li><code><a title="dash_charts.dash_helpers.export_table_as_csv" href="#dash_charts.dash_helpers.export_table_as_csv">export_table_as_csv</a></code></li>
<li><code><a title="dash_charts.dash_helpers.format_unix" href="#dash_charts.dash_helpers.format_unix">format_unix</a></code></li>
<li><code><a title="dash_charts.dash_helpers.get_table" href="#dash_charts.dash_helpers.get_table">get_table</a></code></li>
<li><code><a title="dash_charts.dash_helpers.get_unix" href="#dash_charts.dash_helpers.get_unix">get_unix</a></code></li>
<li><code><a title="dash_charts.dash_helpers.graph_return" href="#dash_charts.dash_helpers.graph_return">graph_return</a></code></li>
<li><code><a title="dash_charts.dash_helpers.json_dumps_compact" href="#dash_charts.dash_helpers.json_dumps_compact">json_dumps_compact</a></code></li>
<li><code><a title="dash_charts.dash_helpers.list_sql_tables" href="#dash_charts.dash_helpers.list_sql_tables">list_sql_tables</a></code></li>
<li><code><a title="dash_charts.dash_helpers.parse_dash_cli_args" href="#dash_charts.dash_helpers.parse_dash_cli_args">parse_dash_cli_args</a></code></li>
<li><code><a title="dash_charts.dash_helpers.rm_brs" href="#dash_charts.dash_helpers.rm_brs">rm_brs</a></code></li>
<li><code><a title="dash_charts.dash_helpers.safe_col_name" href="#dash_charts.dash_helpers.safe_col_name">safe_col_name</a></code></li>
<li><code><a title="dash_charts.dash_helpers.store_reference_tables" href="#dash_charts.dash_helpers.store_reference_tables">store_reference_tables</a></code></li>
<li><code><a title="dash_charts.dash_helpers.uniq_table_id" href="#dash_charts.dash_helpers.uniq_table_id">uniq_table_id</a></code></li>
<li><code><a title="dash_charts.dash_helpers.validate" href="#dash_charts.dash_helpers.validate">validate</a></code></li>
<li><code><a title="dash_charts.dash_helpers.write_csv" href="#dash_charts.dash_helpers.write_csv">write_csv</a></code></li>
<li><code><a title="dash_charts.dash_helpers.write_pretty_json" href="#dash_charts.dash_helpers.write_pretty_json">write_pretty_json</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dash_charts.dash_helpers.DBConnect" href="#dash_charts.dash_helpers.DBConnect">DBConnect</a></code></h4>
<ul class="">
<li><code><a title="dash_charts.dash_helpers.DBConnect.close" href="#dash_charts.dash_helpers.DBConnect.close">close</a></code></li>
<li><code><a title="dash_charts.dash_helpers.DBConnect.database_path" href="#dash_charts.dash_helpers.DBConnect.database_path">database_path</a></code></li>
<li><code><a title="dash_charts.dash_helpers.DBConnect.db" href="#dash_charts.dash_helpers.DBConnect.db">db</a></code></li>
<li><code><a title="dash_charts.dash_helpers.DBConnect.new_table" href="#dash_charts.dash_helpers.DBConnect.new_table">new_table</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dash_charts.dash_helpers.DBConnection" href="#dash_charts.dash_helpers.DBConnection">DBConnection</a></code></h4>
</li>
<li>
<h4><code><a title="dash_charts.dash_helpers.SQLConnection" href="#dash_charts.dash_helpers.SQLConnection">SQLConnection</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>